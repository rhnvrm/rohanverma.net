#+seq_todo: TODO DRAFT DONE
#+hugo_base_dir: ../../
#+HUGO_SECTION: blog/2020
#+hugo_front_matter_format: yaml
#+hugo_custom_front_matter: :type post

#+author: rhnvrm

* TODO Setting up ox-hugo with Doom Emacs :emacs:doomemacs:orgmode:foss:vim:@emacs:@notes:
:PROPERTIES:
:EXPORT_FILE_NAME: hello-world
:EXPORT_DATE: 2020-06-29
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :url blog/2020/06/29/hello-world
:END:

** wip items
- I recently released my blogs [[/projects/bodhi][new theme]] on [[https://themes.gohugo.io/bodhi/][hugo-themes]].
- I had also started to re-learn Emacs for org-mode. I have a fully functional setup of Doom Emacs and have also been able to setup a workflow which works for me.
- My internal writing and documentation has improved as a result.
** Introduction
*** Why I switched to Emacs
**** Doom Emacs
***** Already Configured
***** Don't need to remember bindings
***** Evil Mode
****** Already know vim
****** Have tried spacemacs
**** Org Mode
*** Why Hugo
*** Why ox-hugo
** Setting up
**** https://randomgeekery.org/post/2020/06/ox-hugo-for-the-orgconfig/
** Conclusion

* DONE Generating Go docs using gomarkdoc and pandoc :linux:foss:@notes:golang:@golang:
CLOSED: [2020-11-24 Tue 02:19]
:PROPERTIES:
:EXPORT_FILE_NAME: generating-go-documentation
:EXPORT_DATE: 2020-11-24
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :url blog/2020/11/24/generating-go-documentation
:END:

I recently had to distribute the documentation of an internal library to users.
Go developers are used to their editor to providing them with auto completion,
usually with the help of gopls. A lot of times it is necessary for users to be
able to browse a comprehensive list of methods and data types available for
reference. For open source projects, we rely on [[https://godoc.org/][godoc.org]] and [[https://pkg.go.dev][pkg.go.dev]]. But
unfortunately, it is not easy to host one for internal projects.

After a bit of searching, I found [[https://github.com/princjef/gomarkdoc][princejef/gomarkdoc]]. This project is able to process packages and use the docs, to generate a markdown file. Using this I was able to produce a markdown of the packages I wished to share with the users.

#+BEGIN_SRC sh
# install as a cli-tool
go get -u github.com/princjef/gomarkdoc/cmd/gomarkdoc

# generate the docs using specific packages
gomarkdoc ./pkg/foo \
	./pkg/bar \
	./pkg/lorem/ipsum > docs/user-docs.md
#+END_SRC

This was good enough, but a better way would be to distribute it as a single
=html= file. [[https://pandoc.org/][Pandoc]] is a swiss army knife, which can convert one markup format to
another. Combining this into the pipeline, I was able to generate an =html= file
which has the documentation, which is viewable in the browser and contains links
to the git repository as well.

To make the web document look good, I found two interesting things.

The first being, [[https://github.com/oxalorg/sakura][sakura.css]], which is a =classless= css stylesheet, which can be
applied to any =html= file and make it look like a modern website.

The second useful thing, are a few flags available in =pandoc= which help with making the documentation =html= file truly standalone.

1. [[https://pandoc.org/MANUAL.html#option--css][--css]]: This flag accepts a link to a =CSS= stylesheet
2. [[https://pandoc.org/MANUAL.html#option--self-contained][--self-contained]]: This flag produces the =html= file in a way, such that no external dependency is needed.

Using these flags, we can come up with the following script to generate the =html= file from the markdown file.

#+BEGIN_SRC sh
pandoc docs/user-docs.md \
	--toc \
	--metadata title="My Package - User Docs" \
	-c https://unpkg.com/sakura.css/css/sakura.css \
	--self-contained \
	-o docs/user-docs.html
#+END_SRC

This results in well rendered documentation which is standalone and looks modern as well.

[[file:docs-sample.png]]
* TODO Experiments with OBS in the cloud
:PROPERTIES:
:EXPORT_FILE_NAME: obs-cloud-experiments
:EXPORT_DATE: 2020-11-26
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :url blog/2020/11/25/obs-cloud-experiments
:END:

*** Live streaming
**** Nginx rtmp setup
- Very slow
**** Setup kernel
- https://meetrix.io/blog/aws/changing-default-ubuntu-kernel.html
- =sudo apt-get -y install linux-image-extra-virtual=
- =grep -A100 submenu  /boot/grub/grub.cfg |grep menuentry=
- edit grub default in /etc/default/grub
- =sudo update-grub=
- =sudo reboot=
**** Setup docker
- =sudo apt update && sudo apt install docker.io=
- =sudo groupadd docker &&  sudo usermod -aG docker $USER=
**** Setup OBS
- =apt update=
- =add-apt-repository ppa:obsproject/obs-studio=
- =apt install ffmpeg obs-studio=
**** Tunnel locally
- =ssh -L 6901:127.0.0.1:6901 live-stream-instance=
**** Did not work
Setup container
- =docker run -p 5901:5901 -p 6901:6901 -p 2722:22 -ti lifestorm/obs-server=
**** Final message
After a lot of testing for the streaming setup on multiple instance types on EC2, I think the best and simple way would be to just stream from our local machines directly to youtube. The transcoding on those instances is not good enough and chrome is stuttering, jitsi was fine but no clue what could go wrong. Also, audio does not work yet (I changed the kernel from -aws to -generic, still no progress).

On the otherhand, we tested yesterday with Vishnu and I am able to produce a 1080p OBS stream with zero lag locally. On the actual stream day, we can switch to a 720p stream to be safe.

Also, the lag to operate via VNC after the starting OBS is bad enough to not allow operating the remote OBS, which could cause issues.

In case of an internet issue during the live stream, I tested the nginx-rtmp module for seamless switching by proxying, but the stream from local to that nginx drops a lot of packets whereas directly to youtube it drops nearly zero times. Avoiding this, we can just have a backup OBS on some other machine with a different ISP with everything setup and share the stream-key and start broadcasting from the other machine and stream (again directly to youtube) instead of via this nginx-proxy. A bit riskier and might have a few seconds of disruption, but overall quality would be maintained.

* DONE The x4ivygA51F Rabbit Hole :@notes:
CLOSED: [2020-11-25 Wed 23:25]
:PROPERTIES:
:EXPORT_FILE_NAME: x4ivygA51F-rabbit-role
:EXPORT_DATE: 2020-11-25
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :url blog/2020/11/25/x4ivygA51F-rabbit-hole
:END:

I recently read the blog about the [[https://nordpass.com/most-common-passwords-list/][200 most common passwords of 2020]]. It was
also featured in Jon Snader's [[https://irreal.org/blog/?p=9301][recent blog post]]. When the original post was made,
I had glanced at the mysterious =x4ivygA51F=, which appeared at the 148th spot.
But when I read the blog post again and searched for an update on it, no one had
been able to figure out what that meant.

There were some guesses. Few folks on [[https://www.reddit.com/r/sysadmin/comments/jxtnet/200_worst_passwords_for_2020/][reddit]] and [[https://boards.4channel.org/g/thread/78809839/why-is-x4ivyga51f-the-148th-most-common-password][4chan]], guessed that it might be
password written in another language. This guess was based on a [[https://gizmodo.com/why-ji32k7au4a83-is-a-remarkably-common-password-1833045282][gizmodo article]],
which mentions something similar. To confirm this hypothesis, I tried searching
for Chinese websites if I could find some mention of this. There was little to
no mention of this to be able to confirm this, at least on what is to be found
through the indexed web on Google or Bing.

Although, one interesting finding here that I saw no one talk about was a
post on the forum of a website called 51haoyou. The post on this forum, which
talks about a breach by hackers on January 10, 2019 talks about this specific
password. In a footnote on [[http://www.51haoyou.com/discuzx3.2/thread-4903.html][this post]], it mentions the following:

#+BEGIN_QUOTE
Note: x4i***1F is the trial password originally displayed by discuz, and
x4ivygA51F is the result of my modification of the display program so that the
password is displayed completely. On 2019-10-28, I completed "The server-side
program is added to determine whether the user login password is encrypted on
the client side, otherwise the php program is interrupted", "Improved the Discuz
mobile version, and also realized that the user password is encrypted on the
client side. "Retransmit" time.
#+END_QUOTE

I guess that it could mean that the Discuz forum software by default suggests
this password somewhere on the registration page. Or administratively this is
set to be the default password somewhere by this BB software. Using the Cangjie
input method, I found those keystrokes build and translate to [[https://translate.google.com/?hl=en&tab=TT&authuser=0#view=home&op=translate&sl=zh-CN&tl=en&text=%E7%94%A0%E9%A1%8C1%E7%81%AB][=Question 1=]].
Something similar does come up on the [[http://www.51haoyou.com/discuzx3.2/member.php?mod=register][login page]] this does come up in terms of
security question, although this could be entirely incorrect as I don't know
Chinese or Cangjie. Another guess here is that this is the breach that led to
the inclusion of this password in the list itself.
* DONE The Ethics of Invention                         :@books:books:techpolicy:
CLOSED: [2020-12-20 Sun 03:23]
:PROPERTIES:
:EXPORT_FILE_NAME: ethics-of-invetnion
:EXPORT_DATE: 2020-12-20
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :url blog/2020/12/20/ethics-of-invention
:END:

[[file:ethics_of_invention.jpg][file:ethics_of_invention.jpg]]

The Ethics of Invention by Sheila Jasanoff is not a book on ethics, but rather a
book about the complicated relationship between Technology, Law, and Policy. By
the title, one might think that this is yet another "Techlash" book written to
be read by Tech Luddites. Rather, the book argues for a middle ground between
uncontrolled enthusiasm for technology and the timeless, often understandable,
hatred for technological progress. The main focus of the book is to highlight
the tendency of humans to give or delegate power to technological systems, which
end up governing human behavior without even them noticing it happening under
their noses.

Examples and case studies are abundant in this book. To explain the point, she
takes us through how traffic signals came to dictate the laws of the road.
"Inanimate lights backed by invisible experts and unseen electrical circuits
have stepped in to discipline behavior that was once risky". No one questions
it, and we often just go about our day being governed by them and reshaping our
world over time. Although, it is left to the reader to ponder if it is truly
possible to build democratic consensus around these issues. She compares the
power given to technological systems with legal constitutions. We can comprehend
our delegation to the lawmakers but often the delegation to technological
systems does not compute.

She highlights three major fallacies that we fall prey to while designing
policies and how the over/under reliance on these impacts people.

1. *Technological determinism*: Once a new technology is invented, it "possesses
   an unstoppable momentum, reshaping society to its insatiable demands". It is
   a belief that innovation is always beneficial or good for society and should
   be pushed as far as possible. She takes the example of refrigerants being
   beneficial in the short term but causing Ozone Depletion in the long term. Or
   how automobiles led to enormous progress for humanity in the short term but
   probably caused so many unaccounted externalities in the long term.

2. *Myth of technocracy*: That "only those with specialist knowledge and skills
   can manage and control technology". There are two points she makes here. The
   first being a critique of the technical risk assessment. She argues that
   technology is value-laden from start to finish and the inventors desired end
   clouds our judgment and often forces externalities to be classified as
   "unintended". To expand on this, she says that "Experts’ imaginations are
   often circumscribed by the nature of their expertise.". It is often our first
   instinct to rely on experts but they often "overestimate the degree of
   certainty behind their positions" on a matter and "blind themselves to
   knowledge coming from outside their closed ranks." She goes through the
   example of the Challenger shuttle and the 2008 financial crisis.

3. *Unintended consequences*: "If technological mishaps, accidents, and disasters
   seem unintended, it is because the process of designing technologies is
   rarely exposed to full public view". She asks if it is fair to use such a
   fuzzy word like "unintended", can there ever be /intended/ consequences of a
   technology, and if so shouldn't policy be designed to tackle these in the
   first place? Another problem raised is that intention is fixed at a specific
   moment in time, morally, which would not be static in the long term and is
   bound to change and who is responsible to track these changes.

The rest of the book looks at problems of "risks, inequality, and human dignity"
that need to be addressed if our society is to progress and responsibly grow
alongside our technological innovations. Ending with a bunch of questions,
do we exist to further technology or technology exists to further our goals and
ambitions. Do we rely on technology to solve climate change or do we accept and
deal with the fact that we have mismanaged it in the first place. We need to
dispel our thought process from the three fallacies and start agreeing that
"ethical analysis, political supervision and long impeded systematic thinking"
can be applied to technological innovations.

She argues that we need to rethink tech-policy, where we first look at risk
assessment to anticipate and rather bring in values into our decision making at
an earlier stage. At the same time, she asks us to not rely on "Trickle down
innovation" and look at collective ownership and collective good rather than
treating all tech as extractive and solely for profiteering. Another caution is
to keep ethical discourse public and draw a balance between private discourse so
that it does not spawn further public alienation between views of experts hired
by private bodies and democratic institutions.
* DONE Use of Facial Recognition Tech by Law Enforcement :@uncategorized:techpolicy:opinion:
CLOSED: [2020-11-16 Mon 03:59]
:PROPERTIES:
:EXPORT_FILE_NAME: frt-law-enforcement
:EXPORT_DATE: 2020-11-16
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :url blog/2020/11/16/use-of-facial-recognition-police
:END:

The use of Facial Recognition by law enforcement to identify offenders is one of
the cases where the regulation of the technology lags way behind, and there is
an urgent need to bring about policy to reduce potential pain in our society.
Apart from the serious problems that are inherent with the technology like
mis-identification and minimal mapping between the training sets and the actual
photos. According to a recent report in TechCrunch [1], the Home Minister of
India admitted to using a data set trained on the Aadhaar Database to identify
individuals involved in a recent riot. This software was originally obtained in
the name of a good cause, to identify missing children, although according to
the report [1] the software failed to even distinguish between boys and girls.
Recent advances in AI have made certain model that perform recognition by
training on huge datasets, unfortunately they are considered to be black boxes.
Along with this, there is a question of how in line it is with the Privacy Laws
and the inherent questions of cyber-security. To address these issues, we should
open discourse on these topics with experts. Unlike the approach in the west [2]
to ban the tech, we should try to come up with a middle ground. Ideally, a
policy should be discussed to thoroughly document the process of how the model
was trained and the dataset that was used in the process. After the model is
trained and put into production, there should a mandatory requirement to
disclose the uses of the model along with the false-negatives in a proper
manner. Using this information, there should be regular reviews to revisit the
efficacy of the model. A mechanism should be devised to be able to appeal for
manual review by an expert in case a person who is identified by this system. A
person should also be able to opting out of being incriminated by the use of
this technology. Such mechanisms, in such a policy, would address the privacy
concerns as well.

[1]: https://techcrunch.com/2020/03/11/india-used-facial-recognition-tech-to-identify-1100-individuals-at-a-recent-riot/
[2]: https://securitytoday.com/articles/2019/10/10/california-to-become-third-state-to-ban-facial-recognition-software-in-police-body-cameras.aspx
* DONE Does NPD Governance Framework give Government a backdoor into private companies :@uncategorized:techpolicy:opinion:
CLOSED: [2020-12-03 Thu 04:34]
:PROPERTIES:
:EXPORT_FILE_NAME: npd-backdoor
:EXPORT_DATE: 2020-12-03
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :url blog/2020/12/03/npd-backdoor-govt
:END:

Ministry of Electronics and Information Technology (MEITY) had released a report
[1] on the “Non-Personal Data Governance Framework” in July 2020 [2]. The report
recommends the establishment of a Non-Personal Data Regulatory Authority with an
enabling role as well as enforcing role. [2] Along with this, the report defines
Non Personal Data as: [3]

#+BEGIN_QUOTE
Non-personal data: When the data is not ‘personal data’ (as defined under the
PDP Bill), or the data is without any personally identifiable information (PII).
It could be:

- Data that never related to an identified or identifiable natural person, such
  as data on weather conditions, data from sensors installed on industrial
  machines, data from public infrastructures, etc., or
- Data that was initially personal data but was later made anonymous. “Data
  which are aggregated and to which certain data transformation techniques are
  applied, to the extent that individual specific events are no longer
  identifiable, can be qualified as anonymous data”.
#+END_QUOTE

Every tech company, which collects non-personal data would be obliged to
register itself as a *Data Business*.

Access to non-personal data may be requested for three purposes, one of those
being: [3]

#+BEGIN_QUOTE
1. *Sovereign purposes* such as national security, law enforcement, legal or
   regulatory purposes. These purposes could include mapping physical and cyber
   security vulnerabilities, mapping crime and taking preventive measures, a
   regulator wanting to stay abreast of developments in the sector, or national
   security (via telecommunications metadata, geospatial or financial data,
   etc.)
#+END_QUOTE

Putting two plus two together, it is easy to understand that this could mean
that the government could get private tech companies to anonymize and give data
collected of its users, that could be private in nature, and hand it to them.
Another failure here is that it is clearly understood by the tech community that
using metadata, it is often trivial to de-anonymize data. Now the scope and
urgency of the matter is not specified. Neither is any recommendation given by
the report to limit the usage of this under exceptional circumstances, or maybe
atleast only when warranted by say the judiciary. Even though the report has
mentioned the need of "adequate checks against abuse of power by government or
other representative agencies" there is little emphasis on what these will be.
This was even mentioned in the Medianama article on the concerns [6].

Here I would like to invoke the *Iron Law of Data Collection*, by Jon Snader [4],
which states that no matter what the original rationale given for its collection
new uses will be found for it and will eventually be abused.

#+BEGIN_QUOTE
DEA expresses an interest in providing its agents “ ‘unlimited access to patient
de-identified data’ on re/filled prescriptions, daily supply, payment type,
dosing information and gender, among other characteristics, until at least
2025.” [5]
#+END_QUOTE

He gives a concrete example of how even anonymized data collected for the
medical use is being appropriated by law enforcement and is going to be
essentially abused.

Now the issue here is that, when unlimited and multi-genre data collected by
private entities, lands into the laps of the government; how creative will our
government be?

[1]: https://static.mygov.in/rest/s3fs-public/mygov_159453381955063671.pdf
[2]: https://www.mygov.in/task/share-your-inputs-draft-non-personal-data-governance-framework/
[3]: https://www.medianama.com/2020/07/223-summary-non-personal-data-report-meity/
[4]: https://irreal.org/blog/?p=9319
[5]: https://irreal.org/blog/?p=9321
[6]: https://www.medianama.com/2020/07/223-five-key-concerns-with-indias-non-personal-data-report/

* TODO Economics of AI, Social Networks, and Technology      :techpolicy:@notes:
:PROPERTIES:
:EXPORT_FILE_NAME: econ-ai-social-networks-tech
:EXPORT_DATE: 2020-12-19
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :url blog/2020/12/19/econ-ai-social-networks-tech
:END:

* Footnotes

* COMMENT Local Variables                          :ARCHIVE:
# Local Variables:
# eval: (org-hugo-auto-export-mode)
# End:
